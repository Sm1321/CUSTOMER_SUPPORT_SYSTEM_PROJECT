{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a181348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cac1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\MY_Folder\\MY_Courses\\1.GEN_AI_LIVE_Classes\\ipynb_files\\CUSTOMER_SUPPORT_SYSTEM\\data\\flipkart_product_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f6c8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>1-more flexible2-bass is very high3-sound clar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Super sound and good looking I like that prize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Very much satisfied with the device at this pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Nice headphone, bass was very good and sound i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCFZGAQJGYCYDCM</td>\n",
       "      <td>BoAt Rockerz 235v2 with ASAP charging Version ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Sound quality super battery backup super quali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         product_id                                      product_title  \\\n",
       "0  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "1  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "2  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "3  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "4  ACCFZGAQJGYCYDCM  BoAt Rockerz 235v2 with ASAP charging Version ...   \n",
       "\n",
       "   rating            summary  \\\n",
       "0       5  Terrific purchase   \n",
       "1       5  Terrific purchase   \n",
       "2       5             Super!   \n",
       "3       5             Super!   \n",
       "4       5  Terrific purchase   \n",
       "\n",
       "                                              review  \n",
       "0  1-more flexible2-bass is very high3-sound clar...  \n",
       "1     Super sound and good looking I like that prize  \n",
       "2  Very much satisfied with the device at this pr...  \n",
       "3  Nice headphone, bass was very good and sound i...  \n",
       "4  Sound quality super battery backup super quali...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed226d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_id', 'product_title', 'rating', 'summary', 'review'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84991b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1-more flexible2-bass is very high3-sound clarity is good 4-battery back up to 6 to 8 hour's 5-main thing is fastest charging system is available in that. Only 20 min charge and get long up to 4 hours back up 6-killing look awesome 7-for gaming that product does not support 100% if you want for gaming then I'll recommend you please don't buy but you want for only music then this product is very well for you.. 8-no more wireless headphones are comparing with that headphones at this pric...\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0b4b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "2    5\n",
       "3    5\n",
       "4    5\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"rating\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c03807d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    BoAt Rockerz 235v2 with ASAP charging Version ...\n",
       "1    BoAt Rockerz 235v2 with ASAP charging Version ...\n",
       "2    BoAt Rockerz 235v2 with ASAP charging Version ...\n",
       "3    BoAt Rockerz 235v2 with ASAP charging Version ...\n",
       "4    BoAt Rockerz 235v2 with ASAP charging Version ...\n",
       "Name: product_title, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"product_title\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc9f9087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Terrific purchase\n",
       "1    Terrific purchase\n",
       "2               Super!\n",
       "3               Super!\n",
       "4    Terrific purchase\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"summary\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02be37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Tuple\n",
    "from langchain_core.documents import Document\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from utils.model_loader import ModelLoader\n",
    "from config.config_loader import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2b1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def load_config(config_path: str = \"config/config.yaml\") -> dict:\n",
    "    with open(config_path, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba66bbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DataIngestion pipeline...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'config/config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 122\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Run if this file is executed directly\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 122\u001b[0m     ingestion \u001b[38;5;241m=\u001b[39m DataIngestion()\n\u001b[0;32m    123\u001b[0m     ingestion\u001b[38;5;241m.\u001b[39mrun_pipeline()\n",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m, in \u001b[0;36mDataIngestion.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mInitialize environment variables, embedding model, and set CSV file path.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing DataIngestion pipeline...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_loader\u001b[38;5;241m=\u001b[39mModelLoader()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_env_variables()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_csv_path()\n",
      "File \u001b[1;32mc:\\my_folder\\my_courses\\1.gen_ai_live_classes\\ipynb_files\\customer_support_system\\utils\\model_loader.py:14\u001b[0m, in \u001b[0;36mModelLoader.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     12\u001b[0m load_dotenv()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_env()\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m=\u001b[39mload_config()\n",
      "File \u001b[1;32mc:\\my_folder\\my_courses\\1.gen_ai_live_classes\\ipynb_files\\customer_support_system\\config\\config_loader.py:4\u001b[0m, in \u001b[0;36mload_config\u001b[1;34m(config_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_config\u001b[39m(config_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig/config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      5\u001b[0m         config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config/config.yaml'"
     ]
    }
   ],
   "source": [
    "class DataIngestion:\n",
    "    \"\"\"\n",
    "    Class to handle data transformation and ingestion into AstraDB vector store.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize environment variables, embedding model, and set CSV file path.\n",
    "        \"\"\"\n",
    "        print(\"Initializing DataIngestion pipeline...\")\n",
    "        self.model_loader=ModelLoader()\n",
    "        self._load_env_variables()\n",
    "        self.csv_path = self._get_csv_path()\n",
    "        self.product_data = self._load_csv()\n",
    "        self.config=load_config()\n",
    "\n",
    "    def _load_env_variables(self):\n",
    "        \"\"\"\n",
    "        Load and validate required environment variables.\n",
    "        \"\"\"\n",
    "        load_dotenv()\n",
    "        \n",
    "        required_vars = [\"GOOGLE_API_KEY\", \"ASTRA_DB_API_ENDPOINT\", \"ASTRA_DB_APPLICATION_TOKEN\", \"ASTRA_DB_KEYSPACE\"]\n",
    "        \n",
    "        missing_vars = [var for var in required_vars if os.getenv(var) is None]\n",
    "        if missing_vars:\n",
    "            raise EnvironmentError(f\"Missing environment variables: {missing_vars}\")\n",
    "        \n",
    "        self.google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        self.db_api_endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "        self.db_application_token = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "        self.db_keyspace = os.getenv(\"ASTRA_DB_KEYSPACE\")\n",
    "\n",
    "       \n",
    "\n",
    "    def _get_csv_path(self):\n",
    "        \"\"\"\n",
    "        Get path to the CSV file located inside 'data' folder.\n",
    "        \"\"\"\n",
    "        current_dir = os.getcwd()\n",
    "        csv_path = os.path.join(current_dir, 'data', 'flipkart_product_review.csv')\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found at: {csv_path}\")\n",
    "\n",
    "        return csv_path\n",
    "\n",
    "    def _load_csv(self):\n",
    "        \"\"\"\n",
    "        Load product data from CSV.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.csv_path)\n",
    "        expected_columns = {'product_title', 'rating', 'summary', 'review'}\n",
    "\n",
    "        if not expected_columns.issubset(set(df.columns)):\n",
    "            raise ValueError(f\"CSV must contain columns: {expected_columns}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform_data(self):\n",
    "        \"\"\"\n",
    "        Transform product data into list of LangChain Document objects.\n",
    "        \"\"\"\n",
    "        product_list = []\n",
    "\n",
    "        for _, row in self.product_data.iterrows():\n",
    "            product_entry = {\n",
    "                \"product_name\": row['product_title'],\n",
    "                \"product_rating\": row['rating'],\n",
    "                \"product_summary\": row['summary'],\n",
    "                \"product_review\": row['review']\n",
    "            }\n",
    "            product_list.append(product_entry)\n",
    "\n",
    "        documents = []\n",
    "        for entry in product_list:\n",
    "            metadata = {\n",
    "                \"product_name\": entry[\"product_name\"],\n",
    "                \"product_rating\": entry[\"product_rating\"],\n",
    "                \"product_summary\": entry[\"product_summary\"]\n",
    "            }\n",
    "            doc = Document(page_content=entry[\"product_review\"], metadata=metadata)\n",
    "            documents.append(doc)\n",
    "\n",
    "        print(f\"Transformed {len(documents)} documents.\")\n",
    "        return documents\n",
    "\n",
    "    def store_in_vector_db(self, documents: List[Document]):\n",
    "        \"\"\"\n",
    "        Store documents into AstraDB vector store.\n",
    "        \"\"\"\n",
    "        collection_name=self.config[\"astra_db\"][\"collection_name\"]\n",
    "        vstore = AstraDBVectorStore(\n",
    "            embedding= self.model_loader.load_embeddings(),\n",
    "            collection_name=collection_name,\n",
    "            api_endpoint=self.db_api_endpoint,\n",
    "            token=self.db_application_token,\n",
    "            namespace=self.db_keyspace,\n",
    "        )\n",
    "\n",
    "        inserted_ids = vstore.add_documents(documents)\n",
    "        print(f\"Successfully inserted {len(inserted_ids)} documents into AstraDB.\")\n",
    "        return vstore, inserted_ids\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"\n",
    "        Run the full data ingestion pipeline: transform data and store into vector DB.\n",
    "        \"\"\"\n",
    "        documents = self.transform_data()\n",
    "        vstore, inserted_ids = self.store_in_vector_db(documents)\n",
    "\n",
    "        # Optionally do a quick search\n",
    "        query = \"Can you tell me the low budget headphone?\"\n",
    "        results = vstore.similarity_search(query)\n",
    "\n",
    "        print(f\"\\nSample search results for query: '{query}'\")\n",
    "        for res in results:\n",
    "            print(f\"Content: {res.page_content}\\nMetadata: {res.metadata}\\n\")\n",
    "\n",
    "# Run if this file is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    ingestion = DataIngestion()\n",
    "    ingestion.run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f0920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20cbb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
